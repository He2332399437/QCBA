import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset
from torch.utils.tensorboard import SummaryWriter
from scipy.io import loadmat
import numpy as np
import pandas as pd
from joblib import dump, load
from sklearn.metrics import classification_report, confusion_matrix
from tqdm import tqdm
import pywt
from transformers import AutoTokenizer, AutoModel
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.signal import stft
from scipy.fft import fft, fftfreq
from torch.utils.data import Dataset
import json
# -------------------- 设置参数 --------------------
qwen_model_path = ''
qwen_weight_path = ''
OUTPUT_DIR = ''
save_path = ""
with open("", 'r', encoding='utf-8') as f:
    dataset = json.load(f)
# -------------------- 设置参数 --------------------

class TimeSeriesDataset(Dataset):
    def __init__(self,texts, signals, labels):
        self.texts = texts
        self.signals = signals
        self.labels = labels
    def __len__(self):
        return len(self.labels)
    def __getitem__(self, idx):
        signal = torch.tensor(self.signals[idx], dtype=torch.float32)
        label = self.labels[idx]
        text = self.texts[idx]
        # print("type(signal,label) = ",type(signal),type(label))
        return signal, label, text

def preprocess_data(data, max_len=512):
    texts = []
    signals = []
    labels = []
    for item in data:
        signal = item["signal"][:max_len]
        if len(signal) < max_len:
            signal += [0] * (max_len - len(signal))
        features = item["features"]
        label = int(item["label"])

        signal_str = ",".join([f"{x:.4f}" for x in signal])
        features_str = ", ".join([f"{k}:{v:.4f}" for k, v in features.items()])
        text = f"信号序列: [{signal_str}]; 特征: {{{features_str}}}"

        texts.append(text)
        signals.append(signal)
        labels.append(label)
    return texts, signals, labels

texts, signals, labels = preprocess_data(dataset)
train_dataset = TimeSeriesDataset(texts,signals, labels)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)

class HybridAttention(nn.Module):
    def __init__(self, in_channels, reduction=16):
        super(HybridAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool1d(1)
        self.fc = nn.Sequential(
            nn.Linear(in_channels, in_channels // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(in_channels // reduction, in_channels, bias=False),
            nn.Sigmoid()
        )
        self.spatial = nn.Sequential(
            nn.Conv1d(2, 1, kernel_size=7, padding=3, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        # x: [B, C, N]
        b, c, n = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1)
        x_channel = x * y.expand_as(x)
        max_pool, _ = torch.max(x_channel, dim=1, keepdim=True)
        avg_pool = torch.mean(x_channel, dim=1, keepdim=True)
        pool = torch.cat([max_pool, avg_pool], dim=1)
        spatial_att = self.spatial(pool)
        x_spatial = x_channel * spatial_att.expand_as(x_channel)
        return x_spatial
class HybridConvAttentionClassifier(nn.Module):
    def __init__(self, input_channels, num_classes, kernel_size=3, dropout=0.5):
        super(HybridConvAttentionClassifier, self).__init__()
        self.conv1 = nn.Conv1d(input_channels, 128, kernel_size=kernel_size, padding=kernel_size // 2)
        self.conv2 = nn.Conv1d(128, 64, kernel_size=kernel_size, padding=kernel_size // 2)
        self.hybrid_attention = HybridAttention(64, reduction=16)
        self.fc = nn.Linear(64, num_classes)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        # x: [B, input_channels, N]
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        x = self.hybrid_attention(x)
        x = x.mean(dim=2)
        x = self.dropout(x)
        output = self.fc(x)
        return output

class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, dropout=0.5):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding=kernel_size // 2, bias=False)
        self.bn1 = nn.BatchNorm1d(out_channels)
        self.relu = nn.ReLU()
        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride=1, padding=kernel_size // 2, bias=False)
        self.bn2 = nn.BatchNorm1d(out_channels)
        self.dropout = nn.Dropout(dropout)
        self.residual = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, bias=False) if in_channels != out_channels else nn.Identity()

    def forward(self, x):
        residual = self.residual(x)
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        out = self.dropout(out)
        out += residual
        out = self.relu(out)
        return out

class ConvAttentionClassifier(nn.Module):
    def __init__(self, input_channels, num_classes, kernel_size=3, dropout=0.5):
        super(ConvAttentionClassifier, self).__init__()
        self.conv1 = nn.Conv1d(input_channels, 128, kernel_size=kernel_size, padding=kernel_size // 2)
        self.conv2 = nn.Conv1d(128, 64, kernel_size=kernel_size, padding=kernel_size // 2)
        self.attention_linear = nn.Linear(64, 1)
        self.fc = nn.Linear(64, num_classes)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        attention_weights = F.softmax(self.attention_linear(x), dim=2)
        x = x * attention_weights
        x = x.mean(dim=2)
        x = self.dropout(x)
        output = self.fc(x)
        return output

class WeightedAttention(nn.Module):
    def __init__(self, feature_dim):
        super(WeightedAttention, self).__init__()
        self.attention = nn.Linear(feature_dim, 1)

    def forward(self, x):
        attention_weights = F.softmax(self.attention(x), dim=1)
        weighted_features = (x * attention_weights).sum(dim=1)
        return weighted_features

class AAMSoftmax(nn.Module):
    def __init__(self, in_features, out_features, s=30.0, m=0.2):
        super().__init__()
        self.s = s  
        self.m = m  
        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))
        nn.init.xavier_uniform_(self.weight)

    def forward(self, x):
        cosine = F.linear(F.normalize(x), F.normalize(self.weight))  # [B, C]
        phi = cosine - self.m  
        return self.s * phi
class ParallelProjectConcat(nn.Module):
    def __init__(self, dim, num_classes, dropout=0.2):
        super().__init__()
        self.proj_time = nn.Sequential(nn.Linear(dim, dim), nn.ReLU(), nn.Dropout(dropout))
        self.proj_freq = nn.Sequential(nn.Linear(dim, dim), nn.ReLU(), nn.Dropout(dropout))
        self.proj_wave = nn.Sequential(nn.Linear(dim, dim), nn.ReLU(), nn.Dropout(dropout))
        self.proj_qwen = nn.Sequential(nn.Linear(dim, dim), nn.ReLU(), nn.Dropout(dropout))

        self.fusion_fc = nn.Sequential(
            nn.Linear(dim * 4, dim),
            nn.ReLU(),
            nn.Dropout(dropout)
        )

        self.classifier = AAMSoftmax(dim, num_classes)

    def forward(self, time_feat, freq_feat, wave_feat, qwen_feat):
        t = self.proj_time(time_feat)
        f = self.proj_freq(freq_feat)
        w = self.proj_wave(wave_feat)
        q = self.proj_qwen(qwen_feat)

        fused = torch.cat([t, f, w, q], dim=1)
        fused = self.fusion_fc(fused)
        return self.classifier(fused)

class ResNet_BiGRU_QwenFusion(nn.Module):
    def __init__(self, qwen_model_path, qwen_weight_path, num_classes=10, hidden_dim=128, num_layers=2, dropout=0.5):
        super(ResNet_BiGRU_QwenFusion, self).__init__()

        self.tokenizer = AutoTokenizer.from_pretrained(qwen_model_path, trust_remote_code=True)
        self.qwen_model = AutoModel.from_pretrained(qwen_model_path, trust_remote_code=True)
        self.qwen_model.load_state_dict(torch.load(qwen_weight_path), strict=False) 
        self.qwen_model.eval()  

        self.time_resblock1 = ResidualBlock(1, 32, 3, 1, dropout)
        self.time_resblock2 = ResidualBlock(32, 64, 3, 1, dropout)
        self.time_pool = nn.MaxPool1d(2, 2)

        self.freq_resblock1 = ResidualBlock(1, 32, 3, 1, dropout)
        self.freq_resblock2 = ResidualBlock(32, 64, 3, 1, dropout)
        self.freq_pool = nn.MaxPool1d(2, 2)

        self.wavelet_resblock1 = ResidualBlock(1, 32, 3, 1, dropout)
        self.wavelet_resblock2 = ResidualBlock(32, 64, 3, 1, dropout)
        self.wavelet_pool = nn.MaxPool1d(2, 2)

        self.time_bigru = nn.GRU(64, hidden_dim, num_layers, bidirectional=True, batch_first=True)
        self.freq_bigru = nn.GRU(64, hidden_dim, num_layers, bidirectional=True, batch_first=True)
        self.wavelet_bigru = nn.GRU(64, hidden_dim, num_layers, bidirectional=True, batch_first=True)

        self.time_attention = WeightedAttention(hidden_dim * 2)
        self.freq_attention = WeightedAttention(hidden_dim * 2)
        self.wavelet_attention = WeightedAttention(hidden_dim * 2)

        self.qwen_fc = nn.Linear(self.qwen_model.config.hidden_size, hidden_dim * 2)
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(hidden_dim * 2 * 4, num_classes)
        self.fusion = ParallelProjectConcat(
            dim=hidden_dim * 2,
            num_classes=num_classes,
            dropout=dropout
        )

    def forward(self, x_signal, qwen_texts):
        device = x_signal.device
        signal_input = x_signal[:, :512].unsqueeze(1)
        time = self.time_pool(self.time_resblock2(self.time_pool(self.time_resblock1(signal_input))))
        time = time.permute(0, 2, 1)
        time_out, _ = self.time_bigru(time)
        time_feat = self.time_attention(time_out)

        fft_result = torch.fft.rfft(signal_input.squeeze(1), dim=1)
        mag = torch.abs(fft_result)
        if mag.size(1) < 512:
            mag = F.pad(mag, (0, 512 - mag.size(1)))
        mag = mag.unsqueeze(1)
        freq = self.freq_pool(self.freq_resblock2(self.freq_pool(self.freq_resblock1(mag))))
        freq = freq.permute(0, 2, 1)
        freq_out, _ = self.freq_bigru(freq)
        freq_feat = self.freq_attention(freq_out)

        wavelets = []
        for i in range(signal_input.size(0)):
            try:
                coeff = pywt.wavedec(signal_input[i].cpu().numpy(), "db4", level=4)
                flat = np.concatenate(coeff, axis=0) if coeff else np.zeros(512)
            except:
                flat = np.zeros(512)
            wavelets.append(flat)
        wavelets = torch.tensor(wavelets, dtype=torch.float32, device=device).unsqueeze(1)
        wave = self.wavelet_pool(self.wavelet_resblock2(self.wavelet_pool(self.wavelet_resblock1(wavelets))))
        wave = wave.permute(0, 2, 1)
        wave_out, _ = self.wavelet_bigru(wave)
        wave_feat = self.wavelet_attention(wave_out)

        with torch.no_grad():
            encoding = self.tokenizer(qwen_texts, padding=True, truncation=True, return_tensors="pt").to(device)
            qwen_output = self.qwen_model(**encoding)
            qwen_embed = qwen_output.last_hidden_state[:, 0, :]
            # print("qwen_embed.shape = ",qwen_embed.shape,qwen_embed)
        qwen_feat = F.relu(self.qwen_fc(self.dropout(qwen_embed)))
        logits = self.fusion(time_feat, freq_feat, wave_feat, qwen_feat)      
        return logits

def train_model(model, train_loader, num_epochs, device, writer):

    optimizer = optim.Adam(model.parameters(), lr=0.001)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)
    criterion = nn.CrossEntropyLoss()
    best_train_acc = 0.0 

    for epoch in range(num_epochs):
        print(f"Epoch {epoch + 1}, 当前学习率: {scheduler.get_last_lr()[0]}")
        model.train()
        correct = 0

        for x, y, qwen_texts in tqdm(train_loader, desc=f"Training Epoch {epoch + 1}/{num_epochs}"):
            x = x.to(device)
            y = torch.tensor([int(label) for label in y], dtype=torch.long).to(device)
            optimizer.zero_grad()
            outputs = model(x, qwen_texts)
            loss = criterion(outputs, y)
            loss.backward()
            optimizer.step()
            preds = outputs.argmax(dim=1)
            correct += (preds == y).sum().item()
        scheduler.step()
        train_acc = correct / len(train_loader.dataset)
        print(f"Epoch {epoch + 1}, Loss: {loss.item():.7f}, Train Acc: {train_acc:.7f}")

        writer.add_scalar("Loss/Train", loss.item(), epoch + 1)
        writer.add_scalar("Accuracy/Train", train_acc, epoch + 1)
        writer.add_scalar("LR", scheduler.get_last_lr()[0], epoch + 1)

        if train_acc > best_train_acc:
            best_train_acc = train_acc
            torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, "best_model.pth"))
            print(f"训练准确率提高，保存当前最佳模型，Train Acc: {best_train_acc:.7f}")

    torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, "last_model.pth"))
    print("训练完成，已保存最终模型权重。")
    writer.close()

if __name__ == "__main__":
    print("Starting the training process...")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    writer = SummaryWriter(log_dir=OUTPUT_DIR)
    batch_size = 4 
    num_epochs = 15  

    texts, signals, labels = preprocess_data(dataset)
    train_dataset = TimeSeriesDataset(texts, signals, labels)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    # qwen_model_path = "/home/admin1/git_code/models/Qwen2.5-Math-1.5B-Instruct"
    model = ResNet_BiGRU_QwenFusion(
        qwen_model_path=qwen_model_path,  
        qwen_weight_path=qwen_weight_path,  
        num_classes=10, 
        dropout=0.5 
    )

    model.to(device)

    train_model(model, train_loader, num_epochs, device, writer)
    writer.close()
    print("模型训练完成。")
